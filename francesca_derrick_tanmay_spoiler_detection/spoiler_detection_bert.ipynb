{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Instructions\n",
    "\n",
    "This notebook contains code for Fine-Tuning BERT, including dataset pre-processing and tokenization, hyperparameter searching and final model training and evaluation.\n",
    "\n",
    "Please note that because of the time constraints of fine-tuning, training code calls have been commented out. Instead, this notebook loads our final fine-tuned models from saved checkpoints on disk.\n",
    "\n",
    "This notebook also requires our balanced csv datasets (provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bkyOi4DjCB5z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchetti.f/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, Features, ClassLabel, Value\n",
    "import evaluate\n",
    "from evaluate import evaluator\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets import DatasetDict\n",
    "import wandb\n",
    "from ast import literal_eval\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 85051572224 used for dev 0, reserved 0\n"
     ]
    }
   ],
   "source": [
    "## Util to check GPU memory \n",
    "\n",
    "def check_dev(n):\n",
    "    t = torch.cuda.get_device_properties(n).total_memory\n",
    "    r = torch.cuda.memory_reserved(n)\n",
    "    a = torch.cuda.memory_allocated(n)\n",
    "    f = r-a  # free\n",
    "    print(f\"{a} / {t} used for dev {n}, reserved {r}\")\n",
    "    \n",
    "def check_devs():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        check_dev(i)\n",
    "\n",
    "check_devs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YR9J6iclYFJ6"
   },
   "source": [
    "## Load pre-balanced data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HmfApZNmCEtP"
   },
   "outputs": [],
   "source": [
    "movie_review_df = pd.read_csv('balanced_movie_review.csv')\n",
    "book_review_df = pd.read_csv('balanced_book_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5h_iD78XFYB2",
    "outputId": "0241ec69-c72b-45cd-daf1-3fb08d9d68b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300924 entries, 0 to 300923\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   Unnamed: 0      300924 non-null  int64 \n",
      " 1   review_date     300924 non-null  object\n",
      " 2   movie_id        300924 non-null  object\n",
      " 3   user_id         300924 non-null  object\n",
      " 4   is_spoiler      300924 non-null  bool  \n",
      " 5   review_text     300924 non-null  object\n",
      " 6   rating          300924 non-null  int64 \n",
      " 7   review_summary  300923 non-null  object\n",
      "dtypes: bool(1), int64(2), object(5)\n",
      "memory usage: 16.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179254 entries, 0 to 179253\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   Unnamed: 0        179254 non-null  int64 \n",
      " 1   user_id           179254 non-null  object\n",
      " 2   timestamp         179254 non-null  object\n",
      " 3   review_sentences  179254 non-null  object\n",
      " 4   rating            179254 non-null  int64 \n",
      " 5   has_spoiler       179254 non-null  bool  \n",
      " 6   book_id           179254 non-null  int64 \n",
      " 7   review_id         179254 non-null  object\n",
      "dtypes: bool(1), int64(3), object(4)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "movie_review_df.info()\n",
    "book_review_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-CbHdPigESI"
   },
   "source": [
    "## Preprocess for BERT Classification\n",
    "\n",
    "This section defines utility methods for constructing HF Datasets from our data in DataFrame format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: False, 1: True}\n",
    "label2id = {False: 0, True: 1}\n",
    "spoiler_features = Features({'text': Value('string'), 'label': ClassLabel(names=[True, False])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sents(entry):\n",
    "    '''\n",
    "    Entry: a list of lists\n",
    "    Method for casting the UCSD review sentences to plain string format \n",
    "    (removes sentence-level labels).\n",
    "    '''\n",
    "    review = literal_eval(entry)\n",
    "    return ' '.join([sent[-1] for sent in review])\n",
    "\n",
    "\n",
    "def bert_rename(df, review_type):\n",
    "    '''\n",
    "    Renames DataFrame columns to be consistent in all datasets: [\"label\",\"text\"]\n",
    "    '''\n",
    "    if review_type == \"movie\":\n",
    "        df.rename(inplace=True, columns={\"is_spoiler\": \"label\", \"review_text\":\"text\"})\n",
    "    elif review_type == \"book\":\n",
    "        df.rename(inplace=True, columns={\"has_spoiler\": \"label\", \"review_sentences\":\"text\"})\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "def bert_preproc(df, max_n, review_type):\n",
    "    '''\n",
    "    Receives a DataFrame dataset and clips it to MAX_N number of\n",
    "    label=0 examples and label=1 examples (balanced).\n",
    "    Requires a review_type=[\"movie\",\"book\"] flag.\n",
    "    Returns the preprocessed DataFrame.\n",
    "    '''\n",
    "    df = shuffle(df)\n",
    "    df.reset_index(inplace=True, drop=True) \n",
    "    \n",
    "    bert_rename(df, review_type)\n",
    "    if review_type == \"book\":\n",
    "        df[\"text\"] = df[\"text\"].apply(join_sents).values.tolist()\n",
    "        \n",
    "    df = df.loc[:,[\"label\", \"text\"]]\n",
    "    \n",
    "    no_spoilers_indices = df.index[df['label'] == False][:max_n]\n",
    "    spoilers_indices = df.index[df['label'] == True][:max_n]\n",
    "\n",
    "    mini_spoilers = df.iloc[spoilers_indices]\n",
    "    mini_no_spoilers = df.iloc[no_spoilers_indices]\n",
    "    print(len(mini_spoilers), len(mini_no_spoilers))\n",
    "\n",
    "    preproc_df = mini_spoilers.append(mini_no_spoilers, ignore_index=True)\n",
    "    return preproc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example run for IMDB BERT. \n",
    "For Goodreads BERT, change `movie_review_df` to `book_review_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "toC5dpA0-lZw",
    "outputId": "e0ba7dc0-9b86-4596-98fc-58fd20207e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 3000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   6000 non-null   bool  \n",
      " 1   text    6000 non-null   object\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 52.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>At wits end - this is exactly how i felt after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Advanced beings who have mastered Space Travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>This movie started out promising...a great per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>******WARNING SPOILERS*********Some major plot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>This is a non-linear narrative of a relationsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>False</td>\n",
       "      <td>THE GOOD: performances, technical values, seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>False</td>\n",
       "      <td>As so many reviews attest to, I think that man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>False</td>\n",
       "      <td>Oliver Stone reveals some truths about the war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>False</td>\n",
       "      <td>This is a true story of two great rivals of Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>False</td>\n",
       "      <td>Alright, this movie was amazing. It is truly a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0      True  At wits end - this is exactly how i felt after...\n",
       "1      True  Advanced beings who have mastered Space Travel...\n",
       "2      True  This movie started out promising...a great per...\n",
       "3      True  ******WARNING SPOILERS*********Some major plot...\n",
       "4      True  This is a non-linear narrative of a relationsh...\n",
       "...     ...                                                ...\n",
       "5995  False  THE GOOD: performances, technical values, seve...\n",
       "5996  False  As so many reviews attest to, I think that man...\n",
       "5997  False  Oliver Stone reveals some truths about the war...\n",
       "5998  False  This is a true story of two great rivals of Fo...\n",
       "5999  False  Alright, this movie was amazing. It is truly a...\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REVIEW_TYPE = \"movie\"\n",
    "MAX = 3000\n",
    "\n",
    "preproc_df = bert_preproc(movie_review_df, MAX, REVIEW_TYPE)\n",
    "preproc_df.info()\n",
    "preproc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piAwmgiedgx4"
   },
   "source": [
    "## DistilBERT Finetune Setup\n",
    "\n",
    "Section to define functions used for the Fine-tuning. The following functions will be used by HF Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing functions\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    '''\n",
    "    Computes accuracy for training examples and predictions\n",
    "    '''\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def model_init():\n",
    "    '''\n",
    "    Returns a pretrained (not finetuned) DISTIL_BERT model\n",
    "    '''\n",
    "    checkpoint=\"distilbert-base-uncased\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=2, id2label=id2label, label2id=label2id\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "caaa7c2ad85d41daa2e8e8c1e12750b7",
      "67ef7f160c8c42a087f124f8dbcbe882",
      "5880092e8d784f5fb69205d1050b98aa",
      "74d42549627442f9a0e4b7a10e889d5f",
      "7650b81f3146437fb1ded8802110493d",
      "b4bf3eb2711148cba3d9e87ad3d94a0c",
      "4fa6fa841f994481be280b8184bec470",
      "b26f979adc96422689311537c9180384",
      "9eb6d6389ce64016943f4d0f8f6e387b",
      "c01468b070954dd2b473d8671a5c1e06",
      "5655c13ff67b474c974c25dc51455444",
      "0e89e81bcb924f6da969c320091c4e6a",
      "7fe27eb0eb5c4cea84f598e4122164f6",
      "f4aed048f01d4492b0658f8f9e582d5a",
      "4e64520d431b4e13954f158ce909153b",
      "c7e21baf2ce74029b24f8432ff17ee0f",
      "e1c9a659fde84db8920bc542dbd5126a",
      "51705342d5a84e2d8a06bb2e370d8f62",
      "0482b34c176846169cfd83ed0da004b9",
      "5b14cbf47e164c33ad272f2f74c5002e",
      "780ef7f46631447db2e334eb88d5ca64",
      "a0149009830b4b40a8b713a44ce7e506"
     ]
    },
    "id": "86CqfWENdHZ3",
    "outputId": "6d29b9a8-87f6-4c74-9aa7-7fc3b74d439e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x2aea9f050050> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  2.18ba/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=[True, False], id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize full dataset (to be split into k_folds)\n",
    "data = Dataset.from_pandas(preproc_df, split=\"train\", preserve_index=False, features=spoiler_features)\n",
    "data_tokenized = data.map(tokenize, batched=True)\n",
    "model = model_init()\n",
    "data.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search with WandB\n",
    "\n",
    "This section performs hyperparameter searches using WandB and k-fold cross-validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "9HopaH9YoyY8",
    "outputId": "c79c30e1-f3e5-492f-9d5a-6952b5139220"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = '/home/lucchetti.f/6120/spoiler_detection_bert.ipynb'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = PATH\n",
    "\n",
    "def make_folds(k, dataset):\n",
    "    folds = StratifiedKFold(n_splits=k)\n",
    "    kfolds = folds.split(np.zeros(dataset.num_rows), dataset[\"label\"])\n",
    "    return kfolds\n",
    "\n",
    "def train(\n",
    "        name,\n",
    "        train,\n",
    "        val,\n",
    "        hyperparam):\n",
    "    '''\n",
    "    Trains a model according to hyperparam dict and saves checkpoints.\n",
    "    '''\n",
    "    \n",
    "    with wandb.init(group='imdb', project='spoiler_detection_cls'):\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=name,\n",
    "            learning_rate=hyperparam[\"learning_rate\"],\n",
    "            per_device_train_batch_size=hyperparam[\"per_device_train_batch_size\"],\n",
    "            per_device_eval_batch_size=hyperparam[\"per_device_eval_batch_size\"],\n",
    "            num_train_epochs=hyperparam[\"num_train_epochs\"],\n",
    "            weight_decay=hyperparam[\"weight_decay\"],\n",
    "            report_to='wandb',  \n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\"\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model_init=model_init,\n",
    "            args=training_args,\n",
    "            train_dataset=train,\n",
    "            eval_dataset=val,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "    \n",
    "# BERT authors reccomend: \n",
    "{\n",
    "  \"per_gpu_batch_size\": [16, 32],\n",
    "  \"learning_rate\": [2e-5, 3e-5, 5e-5],\n",
    "  \"num_epochs\": [2, 3, 4]\n",
    "}\n",
    "\n",
    "\n",
    "lr = [2e-5, 3e-5, 5e-5]\n",
    "n_train_batch = [16,4,8]\n",
    "n_eval_batch = [16,4,8]\n",
    "n_epochs = [2,3,4]\n",
    "wd = [0.1,0.2,0.2]\n",
    "\n",
    "\n",
    "def search(k, datasets, name):\n",
    "    kfolds = make_folds(k, datasets)\n",
    "    for i, idx in enumerate(kfolds):\n",
    "        train_idxs = idx[0]\n",
    "        val_idxs = idx[1]\n",
    "        assert(len(set(train_idxs).intersection(set(val_idxs))) == 0), list(set(train_idxs).intersection(set(val_idxs)))\n",
    "\n",
    "        fold_dataset = DatasetDict({\n",
    "            \"train\":datasets.select(train_idxs),\n",
    "            \"validation\":datasets.select(val_idxs)\n",
    "        })\n",
    "        hyperparam = {\n",
    "            \"learning_rate\":lr[i],\n",
    "            \"per_device_train_batch_size\":n_train_batch[i],\n",
    "            \"per_device_eval_batch_size\":n_eval_batch[i],\n",
    "            \"num_train_epochs\":n_epochs[i],\n",
    "            \"weight_decay\":wd[i],\n",
    "        }\n",
    "        train(name, fold_dataset[\"train\"], fold_dataset[\"validation\"], hyperparam)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search(3, data_tokenized, \"hyperparam_search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final BERT Fine-tuning with Optimal Hyperparams\n",
    "\n",
    "Fine-tuning model with hyperparameters from above. To fine-tune a Goodreads model instead,change `data_tokenized` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"final_imdb\"\n",
    "\n",
    "train_test = make_folds(10, data_tokenized)\n",
    "\n",
    "def train_final():\n",
    "    for train_idxs, val_idxs in train_test:\n",
    "        assert(len(set(train_idxs).intersection(set(val_idxs))) == 0), list(set(train_idxs).intersection(set(val_idxs)))\n",
    "        fold_dataset = DatasetDict({\n",
    "                \"train\":data_tokenized.select(train_idxs),\n",
    "                \"test\":data_tokenized.select(val_idxs)\n",
    "        })\n",
    "        hyperparam = {\n",
    "            \"learning_rate\":5e-5,\n",
    "            \"per_device_train_batch_size\":8,\n",
    "            \"per_device_eval_batch_size\":8,\n",
    "            \"num_train_epochs\":4,\n",
    "            \"weight_decay\":0.2,\n",
    "        }\n",
    "        print(len(train_idxs), len(val_idxs))\n",
    "        train(NAME, fold_dataset[\"train\"], fold_dataset[\"test\"], hyperparam)\n",
    "        break\n",
    "        \n",
    "# train_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: OOD test set + inference\n",
    "\n",
    "Evaluating fine-tuned BERT models with preciison, recall, f-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/lucchetti.f/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/lucchetti.f/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/lucchetti.f/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/lucchetti.f/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/lucchetti.f/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", truncation=True)\n",
    "\n",
    "def eval(model, data):\n",
    "\n",
    "    p = task_evaluator.compute(\n",
    "        model_or_pipeline=model,\n",
    "        data=data,\n",
    "        metric=\"precision\",\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_mapping=label2id,\n",
    "        strategy=\"bootstrap\",\n",
    "        n_resamples=10,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    a = task_evaluator.compute(\n",
    "        model_or_pipeline=model,\n",
    "        data=data,\n",
    "        metric=\"accuracy\",\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_mapping=label2id,\n",
    "        strategy=\"bootstrap\",\n",
    "        n_resamples=10,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    r = task_evaluator.compute(\n",
    "        model_or_pipeline=model,\n",
    "        data=data,\n",
    "        metric=\"recall\",\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_mapping=label2id,\n",
    "        strategy=\"bootstrap\",\n",
    "        n_resamples=10,\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    f = task_evaluator.compute(\n",
    "        model_or_pipeline=model,\n",
    "        data=data,\n",
    "        metric=\"f1\",\n",
    "        tokenizer=bert_tokenizer,\n",
    "        label_mapping=label2id,\n",
    "        strategy=\"bootstrap\",\n",
    "        n_resamples=10,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    return p,a,r,f\n",
    "\n",
    "def predict(text, model):\n",
    "    '''\n",
    "    Given a text input and model, return model's class\n",
    "    prediction for the given text.\n",
    "    '''\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return model.config.id2label[predicted_class_id]\n",
    "\n",
    "\n",
    "def get_model(checkpoint):\n",
    "    '''\n",
    "    Returns a model loaded from chekcpoint path\n",
    "    '''\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=2, id2label=id2label, label2id=label2id\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file my_checkpoints/goodreads_checkpoint/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"my_checkpoints/goodreads_checkpoint\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": false,\n",
      "    \"1\": true\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"false\": 0,\n",
      "    \"true\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file my_checkpoints/goodreads_checkpoint/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at my_checkpoints/goodreads_checkpoint.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading configuration file my_checkpoints/imdb_checkpoint/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"my_checkpoints/imdb_checkpoint\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": false,\n",
      "    \"1\": true\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"false\": 0,\n",
      "    \"true\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file my_checkpoints/imdb_checkpoint/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at my_checkpoints/imdb_checkpoint.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "## OOD evaluation\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "\n",
    "MAX = 500\n",
    "eval_movie_data = Dataset.from_pandas(bert_preproc(movie_review_df, MAX, \"movie\"), \n",
    "                                     split=\"test\", preserve_index=False, features=spoiler_features)\n",
    "eval_book_data = Dataset.from_pandas(bert_preproc(book_review_df, MAX, \"book\"), \n",
    "                                     split=\"test\", preserve_index=False, features=spoiler_features)\n",
    "\n",
    "goodreads_model = get_model(\"my_checkpoints/goodreads_checkpoint\")\n",
    "imdb_model = get_model(\"my_checkpoints/imdb_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'precision': {'confidence_interval': (0.5926576324484764,\n",
       "    0.6440405420897869),\n",
       "   'standard_error': 0.018796319412844882,\n",
       "   'score': 0.6203288490284006},\n",
       "  'total_time_in_seconds': 4.68152535893023,\n",
       "  'samples_per_second': 213.60559290626352,\n",
       "  'latency_in_seconds': 0.00468152535893023},\n",
       " {'accuracy': {'confidence_interval': (0.6350219304265113, 0.6660577191643197),\n",
       "   'standard_error': 0.01642119226961171,\n",
       "   'score': 0.661},\n",
       "  'total_time_in_seconds': 4.6791293658316135,\n",
       "  'samples_per_second': 213.71497170014058,\n",
       "  'latency_in_seconds': 0.004679129365831613},\n",
       " {'recall': {'confidence_interval': (0.7797601340662207, 0.8438372892941408),\n",
       "   'standard_error': 0.020247616308683436,\n",
       "   'score': 0.83},\n",
       "  'total_time_in_seconds': 4.650393579155207,\n",
       "  'samples_per_second': 215.03556268492454,\n",
       "  'latency_in_seconds': 0.0046503935791552065},\n",
       " {'f1': {'confidence_interval': (0.6823962825750187, 0.7193803444241105),\n",
       "   'standard_error': 0.01787941234477903,\n",
       "   'score': 0.7100085543199316},\n",
       "  'total_time_in_seconds': 4.659377630800009,\n",
       "  'samples_per_second': 214.62093851111644,\n",
       "  'latency_in_seconds': 0.004659377630800009})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVAL_MODEL = imdb_model\n",
    "EVAL_DATA = eval_book_data\n",
    "eval(EVAL_MODEL, EVAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Omg can't believe Harry actually died at the end.\", EVAL_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Omg this killed me.\", EVAL_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"!!!\", EVAL_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 1,\n",
       " 192,\n",
       " 'I like reading books based upon a concept that is very new to me and this is one of them. Funnily enough, though, as I was reading this book I mentioned it to a friend of mine and she said she might have read it but she wasn\\'t sure so she asked me for details. Not wanting to give any spoilers I told her I think that if she had read it she would have remembered it as it is so different to which she replied that she actually reads a lot of books like that :D So I guess the concept is not as unique as I had thought but to me it was the first book of this kind so I found it interesting :) One of the strongest points of the book to me was that it didn\\'t finish with the captives regaining their freedom as the way they\\'re adjusting is equally interesting. Unfortunately, I felt like it was sometimes just a vehicle for writing maudlin observations about everyday life through the eyes of a child that is naive and \"unspoilt by social norms\" which caused me some eye-rolling.')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "predict(EVAL_DATA[k][\"text\"], EVAL_MODEL), EVAL_DATA[k][\"label\"], len(EVAL_DATA[k][\"text\"].split()), EVAL_DATA[k][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test hypothesis: short sentences score better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3183227 entries, 0 to 3183226\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   label   bool  \n",
      " 1   text    object\n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 27.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>This is a special book.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>It started slow for about the first third, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>This is what I love about good science fiction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>It is a 2015 Hugo winner, and translated from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>For instance the intermixing of Chinese revolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183222</th>\n",
       "      <td>False</td>\n",
       "      <td>I got the ISBN number that's listed as the \"au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183223</th>\n",
       "      <td>False</td>\n",
       "      <td>And there's some talk about the American versi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183224</th>\n",
       "      <td>False</td>\n",
       "      <td>I did notice a few lines here and there which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183225</th>\n",
       "      <td>False</td>\n",
       "      <td>So, yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183226</th>\n",
       "      <td>False</td>\n",
       "      <td>Anyway... this is still one of my faves of Gai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3183227 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "0        False                            This is a special book.\n",
       "1        False  It started slow for about the first third, the...\n",
       "2        False  This is what I love about good science fiction...\n",
       "3        False  It is a 2015 Hugo winner, and translated from ...\n",
       "4        False  For instance the intermixing of Chinese revolu...\n",
       "...        ...                                                ...\n",
       "3183222  False  I got the ISBN number that's listed as the \"au...\n",
       "3183223  False  And there's some talk about the American versi...\n",
       "3183224  False  I did notice a few lines here and there which ...\n",
       "3183225  False                                          So, yeah.\n",
       "3183226  False  Anyway... this is still one of my faves of Gai...\n",
       "\n",
       "[3183227 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# book reviews preprocess by sent\n",
    "\n",
    "def int_to_bool(num):\n",
    "    return num == 1\n",
    "\n",
    "data = book_review_df[\"review_sentences\"].apply(literal_eval).values.tolist()\n",
    "data = [sent for review in data for sent in review]\n",
    "\n",
    "# to df\n",
    "book_review_sent_df = pd.DataFrame(data=data, columns=[\"label\",\"text\"])\n",
    "book_review_sent_df[\"label\"] = book_review_sent_df[\"label\"].apply(int_to_bool).values.tolist()\n",
    "\n",
    "book_review_sent_df.info()\n",
    "book_review_sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'precision': {'confidence_interval': (0.6211466856724185,\n",
       "    0.7755666161661056),\n",
       "   'standard_error': 0.05658150435830794,\n",
       "   'score': 0.7205882352941176},\n",
       "  'total_time_in_seconds': 0.690104128792882,\n",
       "  'samples_per_second': 289.8113366599277,\n",
       "  'latency_in_seconds': 0.0034505206439644095},\n",
       " {'accuracy': {'confidence_interval': (0.6201011511041631, 0.6916698874652987),\n",
       "   'standard_error': 0.03366501646120691,\n",
       "   'score': 0.65},\n",
       "  'total_time_in_seconds': 0.68892377987504,\n",
       "  'samples_per_second': 290.30787707208606,\n",
       "  'latency_in_seconds': 0.0034446188993752},\n",
       " {'recall': {'confidence_interval': (0.44086175909444086, 0.5046917520702033),\n",
       "   'standard_error': 0.04475901819976398,\n",
       "   'score': 0.49},\n",
       "  'total_time_in_seconds': 0.6830449383705854,\n",
       "  'samples_per_second': 292.80650329845525,\n",
       "  'latency_in_seconds': 0.0034152246918529275},\n",
       " {'f1': {'confidence_interval': (0.5260077005526892, 0.6377408232719738),\n",
       "   'standard_error': 0.047597525834103475,\n",
       "   'score': 0.5833333333333334},\n",
       "  'total_time_in_seconds': 0.6812445167452097,\n",
       "  'samples_per_second': 293.58034462507305,\n",
       "  'latency_in_seconds': 0.0034062225837260484})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_preproc = bert_preproc(book_review_sent_df, 100, \"other\")\n",
    "eval_book_sent_data = Dataset.from_pandas(sent_preproc, \n",
    "                                     split=\"test\", preserve_index=False, features=spoiler_features)\n",
    "\n",
    "eval(imdb_model, eval_book_sent_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on sentence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:00<00:00, 15.68ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 6000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NAME = \"final_sent_goodreads\"\n",
    "\n",
    "sent_tokenized = Dataset.from_pandas(bert_preproc(book_review_sent_df, 3000, \"other\"), \n",
    "                                     split=\"train\", \n",
    "                                     preserve_index=False, \n",
    "                                     features=spoiler_features).map(tokenize, batched=True)\n",
    "train_test = make_folds(10, sent_tokenized)\n",
    "print(sent_tokenized)\n",
    "\n",
    "def train_sent():\n",
    "    for train_idxs, val_idxs in train_test:\n",
    "        assert(len(set(train_idxs).intersection(set(val_idxs))) == 0), list(set(train_idxs).intersection(set(val_idxs)))\n",
    "        fold_dataset = DatasetDict({\n",
    "                \"train\":sent_tokenized.select(train_idxs),\n",
    "                \"test\":sent_tokenized.select(val_idxs)\n",
    "        })\n",
    "        hyperparam = {\n",
    "            \"learning_rate\":5e-5,\n",
    "            \"per_device_train_batch_size\":8,\n",
    "            \"per_device_eval_batch_size\":8,\n",
    "            \"num_train_epochs\":4,\n",
    "            \"weight_decay\":0.2,\n",
    "        }\n",
    "        print(len(train_idxs), len(val_idxs))\n",
    "        train(NAME, fold_dataset[\"train\"], fold_dataset[\"test\"], hyperparam)\n",
    "        break\n",
    "        \n",
    "# train_sent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file my_checkpoints/sent_goodreads/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"my_checkpoints/sent_goodreads\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": false,\n",
      "    \"1\": true\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"false\": 0,\n",
      "    \"true\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file my_checkpoints/sent_goodreads/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at my_checkpoints/sent_goodreads.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'precision': {'confidence_interval': (0.6267949204298924,\n",
       "    0.6677331133349331),\n",
       "   'standard_error': 0.017127604456405814,\n",
       "   'score': 0.6415094339622641},\n",
       "  'total_time_in_seconds': 4.911277273669839,\n",
       "  'samples_per_second': 203.6130204582754,\n",
       "  'latency_in_seconds': 0.004911277273669839},\n",
       " {'accuracy': {'confidence_interval': (0.6154096537376601, 0.6573069871424213),\n",
       "   'standard_error': 0.015319196381591895,\n",
       "   'score': 0.635},\n",
       "  'total_time_in_seconds': 4.902495447546244,\n",
       "  'samples_per_second': 203.9777518815467,\n",
       "  'latency_in_seconds': 0.004902495447546244},\n",
       " {'recall': {'confidence_interval': (0.561926035781331, 0.6317377375187047),\n",
       "   'standard_error': 0.023397106559815143,\n",
       "   'score': 0.612},\n",
       "  'total_time_in_seconds': 4.926526803523302,\n",
       "  'samples_per_second': 202.98275841812745,\n",
       "  'latency_in_seconds': 0.004926526803523302},\n",
       " {'f1': {'confidence_interval': (0.5923806774802787, 0.643556876527997),\n",
       "   'standard_error': 0.01834349033995444,\n",
       "   'score': 0.6264073694984647},\n",
       "  'total_time_in_seconds': 4.901209268718958,\n",
       "  'samples_per_second': 204.03127986848287,\n",
       "  'latency_in_seconds': 0.004901209268718958})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_model = get_model(\"my_checkpoints/sent_goodreads\")\n",
    "eval(sent_model, eval_movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'precision': {'confidence_interval': (0.6236965406373279,\n",
       "    0.6884792730416581),\n",
       "   'standard_error': 0.02213215680527061,\n",
       "   'score': 0.6480446927374302},\n",
       "  'total_time_in_seconds': 4.895009087398648,\n",
       "  'samples_per_second': 204.28971267373672,\n",
       "  'latency_in_seconds': 0.004895009087398648},\n",
       " {'accuracy': {'confidence_interval': (0.5816493599492131, 0.6268100769834994),\n",
       "   'standard_error': 0.01627847931745743,\n",
       "   'score': 0.606},\n",
       "  'total_time_in_seconds': 4.907166248187423,\n",
       "  'samples_per_second': 203.78359921459224,\n",
       "  'latency_in_seconds': 0.004907166248187422},\n",
       " {'recall': {'confidence_interval': (0.43628508689901213, 0.4980803674931558),\n",
       "   'standard_error': 0.022566200502435,\n",
       "   'score': 0.464},\n",
       "  'total_time_in_seconds': 4.919306471943855,\n",
       "  'samples_per_second': 203.28068716663057,\n",
       "  'latency_in_seconds': 0.0049193064719438555},\n",
       " {'f1': {'confidence_interval': (0.511715839150287, 0.574288045228997),\n",
       "   'standard_error': 0.02128639443387322,\n",
       "   'score': 0.5407925407925408},\n",
       "  'total_time_in_seconds': 4.907322371378541,\n",
       "  'samples_per_second': 203.77711597517995,\n",
       "  'latency_in_seconds': 0.00490732237137854})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(goodreads_model, eval_movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation\n",
    "\n",
    "Extract new unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=150\n",
    "m = 4000\n",
    "test_goodreads = Dataset.from_pandas(bert_preproc(book_review_df, m+n, \"book\", min_n=m), \n",
    "                                     split=\"test\", preserve_index=False, features=spoiler_features)\n",
    "test_imdb = Dataset.from_pandas(bert_preproc(movie_review_df, m+n, \"movie\", min_n=m), \n",
    "                                     split=\"test\", preserve_index=False, features=spoiler_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(goodreads_model, test_goodreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(goodreads_model,test_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(sent_model, test_goodreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(sent_model, test_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(imdb_model, test_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(imdb_model, test_goodreads)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0482b34c176846169cfd83ed0da004b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e89e81bcb924f6da969c320091c4e6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7fe27eb0eb5c4cea84f598e4122164f6",
       "IPY_MODEL_f4aed048f01d4492b0658f8f9e582d5a",
       "IPY_MODEL_4e64520d431b4e13954f158ce909153b"
      ],
      "layout": "IPY_MODEL_c7e21baf2ce74029b24f8432ff17ee0f"
     }
    },
    "4e64520d431b4e13954f158ce909153b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_780ef7f46631447db2e334eb88d5ca64",
      "placeholder": "​",
      "style": "IPY_MODEL_a0149009830b4b40a8b713a44ce7e506",
      "value": " 200/200 [00:00&lt;00:00, 1234.06 examples/s]"
     }
    },
    "4fa6fa841f994481be280b8184bec470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51705342d5a84e2d8a06bb2e370d8f62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5655c13ff67b474c974c25dc51455444": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5880092e8d784f5fb69205d1050b98aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b26f979adc96422689311537c9180384",
      "max": 800,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9eb6d6389ce64016943f4d0f8f6e387b",
      "value": 800
     }
    },
    "5b14cbf47e164c33ad272f2f74c5002e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67ef7f160c8c42a087f124f8dbcbe882": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4bf3eb2711148cba3d9e87ad3d94a0c",
      "placeholder": "​",
      "style": "IPY_MODEL_4fa6fa841f994481be280b8184bec470",
      "value": "Map: 100%"
     }
    },
    "74d42549627442f9a0e4b7a10e889d5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c01468b070954dd2b473d8671a5c1e06",
      "placeholder": "​",
      "style": "IPY_MODEL_5655c13ff67b474c974c25dc51455444",
      "value": " 800/800 [00:00&lt;00:00, 1475.54 examples/s]"
     }
    },
    "7650b81f3146437fb1ded8802110493d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "780ef7f46631447db2e334eb88d5ca64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fe27eb0eb5c4cea84f598e4122164f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1c9a659fde84db8920bc542dbd5126a",
      "placeholder": "​",
      "style": "IPY_MODEL_51705342d5a84e2d8a06bb2e370d8f62",
      "value": "Map: 100%"
     }
    },
    "9eb6d6389ce64016943f4d0f8f6e387b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a0149009830b4b40a8b713a44ce7e506": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b26f979adc96422689311537c9180384": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4bf3eb2711148cba3d9e87ad3d94a0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c01468b070954dd2b473d8671a5c1e06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7e21baf2ce74029b24f8432ff17ee0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "caaa7c2ad85d41daa2e8e8c1e12750b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67ef7f160c8c42a087f124f8dbcbe882",
       "IPY_MODEL_5880092e8d784f5fb69205d1050b98aa",
       "IPY_MODEL_74d42549627442f9a0e4b7a10e889d5f"
      ],
      "layout": "IPY_MODEL_7650b81f3146437fb1ded8802110493d"
     }
    },
    "e1c9a659fde84db8920bc542dbd5126a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4aed048f01d4492b0658f8f9e582d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0482b34c176846169cfd83ed0da004b9",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b14cbf47e164c33ad272f2f74c5002e",
      "value": 200
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
